{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langfuse\n",
      "  Downloading langfuse-2.50.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from langfuse) (4.4.0)\n",
      "Collecting backoff>=1.10.0 (from langfuse)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from langfuse) (0.27.0)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from langfuse) (3.7)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from langfuse) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from langfuse) (2.8.2)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from langfuse) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/teihiroki/Repository/private/gpt-frameworks/llama_index/.venv/lib/python3.12/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (4.12.2)\n",
      "Downloading langfuse-2.50.2-py3-none-any.whl (213 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: backoff, langfuse\n",
      "Successfully installed backoff-2.2.1 langfuse-2.50.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from langfuse.llama_index import LlamaIndexCallbackHandler\n",
    "\n",
    "langfuse_callback_manager = LlamaIndexCallbackHandler()\n",
    "Settings.callback_manager = CallbackManager([langfuse_callback_manager])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: who is the president of the United States?\n",
      "As of my last update in October 2023, the President of the United States is Joe Biden. He was inaugurated as the 46th president on January 20, 2021. For the most current information, please verify with a reliable and up-to-date source.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# import and define tools\n",
    "\n",
    "# initialize llm\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# initialize openai agent\n",
    "agent = OpenAIAgent.from_tools([], llm=llm, verbose=True)\n",
    "response = agent.chat(\"who is the president of the United States?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The INTP character is known for being quiet on the surface but constantly engaging in deep thoughts and analysis internally. They enjoy pondering over various ideas and are skilled at identifying the essence of things and tackling abstract problems. INTPs are innovative and logical thinkers who are passionate about challenging existing beliefs and creating new logical models. They value precise communication, dislike lengthy discussions, but can become talkative when discussing their areas of expertise. Additionally, they are calm in crises, motivated by challenges, but may appear arrogant due to their tendency to overlook mundane details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.path.join(os.getenv('PWD'), \"practice/query_engine/simple_query.ipynb\")\n",
    "\n",
    "%run $file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
